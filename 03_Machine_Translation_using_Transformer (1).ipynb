{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShoJG0g52_DC",
        "outputId": "6b4a1368-7ffe-4768-9a40-5407dda81611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k00bnBRS5ybA",
        "outputId": "35a9df59-c646-4193-fb0b-fd369d412d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for english language\n",
        "!python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywD_QM_b7kSk",
        "outputId": "381e7d2f-d41e-49ca-dfd2-43d1a5e582c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for german language\n",
        "!python3 -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE86zHQB7mwx",
        "outputId": "02d9e274-c062-43ca-ff46-f290693cac82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf0CGCiG5DY4"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diVxv-En5DY7",
        "outputId": "72d109cc-4d40-4d1e-e5c2-a4db52dbc637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEjBmsY45DY9"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O1iDdV425DY9",
        "outputId": "98189947-f9ad-4e3f-83cd-8710f07e1b75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_G78pfg35DY9",
        "outputId": "eabdb125-9a8d-431b-d658-e2cf63aaba16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.16.0+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "-q4gxd3w5DY-"
      },
      "source": [
        "## Loading the Dataset\n",
        "\n",
        "Here we are translating English to German."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zm0uaAk5DY-"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'de'\n",
        "\n",
        "train = Multi30k(split=('train'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C75MmEQp5DY-",
        "outputId": "56b28ed0-cd4c-4b37-bf8b-7d2ec5721a47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShardingFilterIterDataPipe"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#so this is a datapipe object\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "kYDiAfn-5DY_"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi7wFYOI5DY_",
        "outputId": "414e25c5-e961-4196-aeb7-24a5de6a2a18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Two young, White males are outside near many bushes.',\n",
              " 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#let's take a look at one example of train\n",
        "sample = next(iter(train))\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_60Jk5Y_5DY_",
        "outputId": "b41b0fbb-d0a4-4e12-8806-4f1366063904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29001"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_size = len(list(iter(train)))\n",
        "train_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtgQwKsL5DZA"
      },
      "source": [
        "Since there are so many samples, we split them into train, validation and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22bvCGXw5DZA"
      },
      "outputs": [],
      "source": [
        "train, val, test = train.random_split(total_length=train_size, weights = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}, seed=999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv-htz4z5DZA",
        "outputId": "9b73d13f-8aa8-4a49-9b7b-ddb3d7dbe36d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20301"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_size = len(list(iter(train)))\n",
        "train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bplLJDT5DZA",
        "outputId": "c1d3462f-71d8-4845-deb9-de1642d388f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5800"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "val_size = len(list(iter(val)))\n",
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPs1SdpF5DZA",
        "outputId": "e22b6155-7f1e-4f6d-986b-0f23b95b367e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2900"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "test_size = len(list(iter(test)))\n",
        "test_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "ZAAvnXT4BI0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizing"
      ],
      "metadata": {
        "id": "ZV-Z7ayFpukI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "jZVUPfax5DZB"
      },
      "source": [
        "Since we have two languages, let's create two different representations for tokens. Also, let's create two dicts: one for holding our tokenizers and one for holding all the vocabs with assigned numbers for each unique word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4ai-Qa85DZB"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XXSJsAQ5DZB"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atsPipnN5DZB",
        "outputId": "31942ded-25d8-4233-e242-2e588604061d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  Two young, White males are outside near many bushes.\n",
            "Tokenization:  ['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[0])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-APYBT2J5DZB"
      },
      "source": [
        "Then we define a function to tokenize our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rrd6YU35DZB"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d7ynNoa5DZB"
      },
      "source": [
        "Before we tokenize, let's define some special symbols so our neural network understand the embeddings of these symbols, namely the unknown, the padding, the start of sentence, and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeNMjuP35DZC"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to integers (Numericalization)"
      ],
      "metadata": {
        "id": "2AdgOytzC1_Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "CAxG7X2F5DZC"
      },
      "source": [
        "Next we gonna create function that turn these tokens into integers. Here we use built-in function <code>build_vocab_from_iterator</code> which accepts iterator that yield list or iterator of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phQOHFsG5DZC",
        "outputId": "7516d49f-2c9c-4b46-9664-36c4fc4832b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln),\n",
        "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrOgpYqp5DZC",
        "outputId": "86317cca-c0a7-43a7-cca7-58cc2abf5434"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1891, 10, 4, 5114, 3164, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#see some example\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknown', 'word', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwzfKq8VDdZg",
        "outputId": "115dddf0-52c5-49fb-c3b1-e8c51112742e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1891, 10, 4, 0, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Hifu51D5DZC",
        "outputId": "7f72ecb7-195d-4231-8d9f-64553c4d7a23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'here'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "#print 1816, for example\n",
        "mapping[1891]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rPLz_jZY5DZC",
        "outputId": "b3f68efb-ee30-4eed-cfae-366dd22b2885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]\n",
        "#they will all map to <unk> which has 0 as integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmL4LhGL5DZE",
        "outputId": "dcfa7d21-c8fa-40f4-8b11-173e209280af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puaSoNSv5DZF",
        "outputId": "94e21c56-154d-436b-d8f7-c3c4b311c30c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5174"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataloader"
      ],
      "metadata": {
        "id": "JmpzLuD-EdQo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Db-U6oE55DZF"
      },
      "source": [
        "The <code>collate_fn</code> we used here also returns the length of sentence. It is required for <code>packed_padded_sequence</code>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RFUmWjR5DZF"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first = True) #<----need this because we use linear layers mostly\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX, batch_first = True)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsuFHEMC5DZF"
      },
      "source": [
        "Then we create train, val, and test dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD89ulZW5DZF"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val,   batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11IvC5S5DZG"
      },
      "source": [
        "Let's check the train loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QP9j-Xy5DZG"
      },
      "outputs": [],
      "source": [
        "for en, _, de in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odr0F8kL5DZG",
        "outputId": "3b5c0443-0888-469d-d0b6-1c6dc6c906de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([64, 24])\n",
            "German shape:  torch.Size([64, 27])\n"
          ]
        }
      ],
      "source": [
        "print(\"English shape: \", en.shape)  # (batch_size, seq len)\n",
        "print(\"German shape: \", de.shape)   # (batch_size, seq len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIdu6KF05DZG"
      },
      "source": [
        "## Designing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfjlWMMT5DZK"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ep92hrF5DZK"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]   #if the token is padding, it will be 1, otherwise 0\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src     = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        _src    = self.feedforward(src)\n",
        "        src     = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        #src: [batch_size, src len, hid dim]\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8eLbkuF5DZK"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0Myvaha5DZK"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 100):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                           for _ in range(n_layers)])\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(self.device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len    = src.shape[1]\n",
        "\n",
        "        pos        = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, src_len]\n",
        "\n",
        "        src        = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        #src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "        return src\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutli-head Attention Layer"
      ],
      "metadata": {
        "id": "MxXQyIgL69lg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVGxIP8b5DZK"
      },
      "source": [
        "$$ \\text{Attention}(Q, K, V) = \\text{Softmax} \\big( \\frac{QK^T}{\\sqrt{d_k}}\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\\big)V $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptWYtBtL5DZK"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        assert hid_dim % n_heads == 0\n",
        "        self.hid_dim  = hid_dim\n",
        "        self.n_heads  = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k     = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.fc_o     = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout  = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale    = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        #src, src, src, src_mask\n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        #Q=K=V: [batch_size, src len, hid_dim]\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        #Q = [batch_size, n heads, query len, head_dim]\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        #Q = [batch_size, n heads, query len, head_dim] @ K = [batch_size, n heads, head_dim, key len]\n",
        "        #energy = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        #for making attention to padding to 0\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        #attention = [batch_size, n heads, query len, key len]\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        #[batch_size, n heads, query len, key len] @ [batch_size, n heads, value len, head_dim]\n",
        "        #x = [batch_size, n heads, query len, head dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()  #we can perform .view\n",
        "        #x = [batch_size, query len, n heads, head dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch_size, query len, hid dim]\n",
        "\n",
        "        return x, attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhf64ehN5DZL"
      },
      "source": [
        "### Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzMJZg2I5DZL"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, src len, hid dim]\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "T8Z3Xy135DZL"
      },
      "source": [
        "### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKAAsXm15DZL"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm  = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm        = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention       = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention    = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward          = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout              = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        trg     = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        trg             = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "        #attention = [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        _trg = self.feedforward(trg)\n",
        "        trg  = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        #trg = [batch_size, trg len, hid dim]\n",
        "\n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOjcemGI5DZL"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF7AUBhV5DZL"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device,max_length = 100):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        self.layers        = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                            for _ in range(n_layers)])\n",
        "        self.fc_out        = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout       = nn.Dropout(dropout)\n",
        "        self.scale         = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len    = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        #pos: [batch_size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #trg: [batch_size, trg len, hid dim]\n",
        "        #attention: [batch_size, n heads, trg len, src len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "        #output = [batch_size, trg len, output_dim]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuiKKUXG5DZM"
      },
      "source": [
        "### Putting them together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i32EMa75DZM"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "CLiRZLt35DZM"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcBa-Kf85DZM"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo4n5Ups5DZM",
        "outputId": "7d8ecb2c-f9ff-435e-98c4-b11076aebc0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(5174, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(6433, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=6433, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "hid_dim = 256\n",
        "enc_layers = 3\n",
        "dec_layers = 3\n",
        "enc_heads = 8\n",
        "dec_heads = 8\n",
        "enc_pf_dim = 512\n",
        "dec_pf_dim = 512\n",
        "enc_dropout = 0.1\n",
        "dec_dropout = 0.1\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "enc = Encoder(input_dim,\n",
        "              hid_dim,\n",
        "              enc_layers,\n",
        "              enc_heads,\n",
        "              enc_pf_dim,\n",
        "              enc_dropout,\n",
        "              device)\n",
        "\n",
        "dec = Decoder(output_dim,\n",
        "              hid_dim,\n",
        "              dec_layers,\n",
        "              dec_heads,\n",
        "              dec_pf_dim,\n",
        "              enc_dropout,\n",
        "              device)\n",
        "\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "TRG_PAD_IDX = PAD_IDX\n",
        "\n",
        "model = Seq2SeqTransformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWft0J4A5DZN",
        "outputId": "e0e38ee3-c9d8-48dc-da99-a79f1b5d4b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324544\n",
            " 25600\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "1646848\n",
            " 25600\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "1646848\n",
            "  6433\n",
            "______\n",
            "8629537\n"
          ]
        }
      ],
      "source": [
        "#we can print the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5WxAHg65DZN"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkS4wdby5DZP"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_len, trg in loader:\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #trg[:, :-1] remove the eos, e.g., \"<sos> I love sushi\" since teaching forcing, the input does not need to have eos\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg    = [batch size, trg len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.reshape(-1, output_dim)\n",
        "        trg = trg[:,1:].reshape(-1) #trg[:, 1:] remove the sos, e.g., \"i love sushi <eos>\" since in teaching forcing, the output does not have sos\n",
        "\n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg    = [batch size * trg len - 1]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFDWfxvP5DZP"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for src, src_len, trg in loader:\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDke72AG5DZP"
      },
      "source": [
        "Finally, we train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGHKvwN45DZQ",
        "outputId": "334eb1d3-bab4-43ec-a705-b78dd4d4d966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttLDnVdj5DZQ"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRqQi_5M5DZQ",
        "outputId": "ffc2a396-127f-46a4-a5ea-cb4275fc627b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 16s\n",
            "\tTrain Loss: 4.195 | Train PPL:  66.371\n",
            "\t Val. Loss: 3.185 |  Val. PPL:  24.176\n",
            "Epoch: 02 | Time: 0m 14s\n",
            "\tTrain Loss: 2.890 | Train PPL:  17.993\n",
            "\t Val. Loss: 2.570 |  Val. PPL:  13.061\n",
            "Epoch: 03 | Time: 0m 17s\n",
            "\tTrain Loss: 2.304 | Train PPL:  10.013\n",
            "\t Val. Loss: 2.245 |  Val. PPL:   9.440\n",
            "Epoch: 04 | Time: 0m 15s\n",
            "\tTrain Loss: 1.922 | Train PPL:   6.837\n",
            "\t Val. Loss: 2.064 |  Val. PPL:   7.878\n",
            "Epoch: 05 | Time: 0m 15s\n",
            "\tTrain Loss: 1.640 | Train PPL:   5.154\n",
            "\t Val. Loss: 1.961 |  Val. PPL:   7.106\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 5\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'{model.__class__.__name__}.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting loss and accuracy"
      ],
      "metadata": {
        "id": "4_oexkuklx5P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "-nzwOmeU5DZQ",
        "outputId": "1dcf63e9-2710-4f55-8e2f-8eb6874da4c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVOEqHcj5DZQ",
        "outputId": "ffcab88a-4cf3-4013-88a5-2bc444de4a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 1.942 | Test PPL:   6.971 |\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjoSUC5k5DZQ"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5_U6UjTG5DZQ",
        "outputId": "6b0bf861-4e0a-4a23-c701-479e3e0b2ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Two young, White males are outside near many bushes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "sample[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4nAIm-_z5DZR",
        "outputId": "8d82eb01-ee2e-4e98-a412-5b78093e9dfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XETLveA5DZR",
        "outputId": "0eea9c52-4a93-40fe-a5ad-f02daec1701d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   19,   25,   15, 1069,  842,   17,   56,   84,  331, 1623,    5,\n",
              "           3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKZRmkIC5DZR",
        "outputId": "8478fea0-84c4-448b-8663-ad112e12fc92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   21,   83,  262,   32,   89,   22,   91,    7,   16,  115,    0,\n",
              "        2893,    4,    3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDJ5_QJc5DZR"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(1, -1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfma4WNG5DZR"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRTlGjUH5DZR",
        "outputId": "88682c5d-8cfc-4d9a-9070-380cdef23fd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 13]), torch.Size([1, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mk18ag45DZR"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA0ORxbu5DZR"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, trg_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeUs3t295DZS",
        "outputId": "7d7bfbf6-d5cc-45a8-e1fe-308d46307771"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 15, 6433])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "output.shape #batch_size, trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8E-pWiF5DZS"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al0Td4eA5DZS"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh7aIP0X5DZS",
        "outputId": "0498ec4f-5787-40d1-9a18-e5f9603e4620"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 6433])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pehBrMyL5DZS"
      },
      "source": [
        "Then we just take the top token with highest probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6ErZN2q5DZS"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLuQaKE65DZS",
        "outputId": "728ecfb6-3ba5-425c-a6da-d430b6067612"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 21,  83,  32,  32,   9,  22,  91,  53,  16, 115,  24,  24,   4,   3,\n",
              "          4], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeqZe2qK5DZT"
      },
      "source": [
        "We get the mapping of the target language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfSBXOFn5DZT"
      },
      "outputs": [],
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhhx6cSg5DZT",
        "outputId": "5019d1a3-01af-4d58-b49a-fd8f62979875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zwei\n",
            "junge\n",
            "Männer\n",
            "Männer\n",
            ",\n",
            "im\n",
            "Freien\n",
            "neben\n",
            "der\n",
            "Nähe\n",
            "von\n",
            "von\n",
            ".\n",
            "<eos>\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "714d3f4db9a58ba7d2f2a9a4fffe577af3df8551aebd380095064812e2e0a6a4"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}